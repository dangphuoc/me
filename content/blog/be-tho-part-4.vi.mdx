---
title: "Bé Thỏ (Phần 4) - Cuộc chiến không có kẻ thắng"
title_vi: "Bé Thỏ (Phần 4) - Cuộc chiến không có kẻ thắng"
title_en: "Little Rabbit (Part 4) - A War Without Winners"
excerpt_vi: "Khi mọi metrics đều xanh, mọi team đều đúng, nhưng hệ thống vẫn chết. Câu chuyện về những cuộc họp căng thẳng, những cái tôi va chạm, và một câu hỏi vẫn chưa có lời đáp."
excerpt_en: "When all metrics are green, every team is right, but the system still dies. A story of tense meetings, clashing egos, and a question that remains unanswered."
date: 2025-01-18
tags:
  - RabbitMQ
  - Little's Law
  - Architecture
  - Performance
  - Series Bé Thỏ
thumbnail: https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800
---

# Bé Thỏ (Phần 4) - Cuộc chiến không có kẻ thắng

## Phòng họp tầng 7

Thứ Năm. 9 giờ sáng. Phòng họp tầng 7.

Đây là cuộc họp thứ tư trong tháng về cùng một vấn đề. Không khí nặng nề như trước cơn bão. Trên bàn, những ly cà phê nguội ngắt. Trên màn hình, biểu đồ latency đỏ lòm như vết thương không lành.

Tôi ngồi một góc, quan sát. Anh Khoa - Tech Lead team Transaction - ngồi đối diện anh Đạt, Tech Director phụ trách Profile Service. Giữa họ là khoảng cách của hai mét bàn họp, nhưng có lẽ xa hơn thế rất nhiều.

![Meeting Room](https://images.unsplash.com/photo-1552581234-26160f608093?w=800)

## "Vấn đề không nằm ở chỗ tôi"

Anh Khoa lên tiếng trước, giọng cố giữ bình tĩnh nhưng không giấu được sự mệt mỏi:

> "Tôi đã nói rồi. Mỗi ngày mùng 5, mùng 10 - ngày lương, ngày thanh toán - latency gọi qua Profile tăng gấp 5 lần. Request của tôi gửi đi, chờ mãi không có response. SLA 200ms, thực tế 800ms đến 1 giây. Khách hàng timeout, giao dịch fail. Đây là data, không phải cảm tính."

Anh Đạt nhìn thẳng, không chớp mắt:

> "Và tôi cũng đã nói. Bên tôi xử lý trong **40 millisecond**. Bốn mươi. Request vào, xử lý, response ra. CPU bình thường. Memory bình thường. Không có gì bất thường. Data của tôi cũng là data."

Im lặng.

Anh Hiền từ team DevOps - người đã theo dõi RabbitMQ suốt 3 năm - lên tiếng:

> "Tôi check RabbitMQ rồi. Message rate ổn. Queue depth không cao. Memory, disk đều trong ngưỡng. Erlang processes không có spike bất thường. Mọi thứ... xanh."

Ba người, ba góc nhìn, ba bộ data. Và tất cả đều **đúng**.

## Khi ai cũng đúng, vậy ai sai?

Đây là loại vấn đề khó chịu nhất trong distributed systems.

Không có error log đỏ chói để debug. Không có server crash để restart. Không có memory leak để fix. Mọi thứ trông hoàn toàn bình thường - cho đến khi nhìn vào trải nghiệm của end user.

Transaction Service gọi Profile Service qua RabbitMQ RPC. Giữa họ là:
- Một con HAProxy
- Một cluster RabbitMQ
- Network switches
- Và hàng trăm biến số khác mà không ai đo được

Ai đó trong chuỗi này đang nói dối. Hoặc không ai nói dối cả - nhưng sự thật vẫn nằm đâu đó, chờ được khám phá.

![Mystery](https://images.unsplash.com/photo-1509475826633-fed577a2c71b?w=800)

## Những ngày cao điểm

Pattern này lặp đi lặp lại suốt 3 tháng.

Ngày thường: mọi thứ êm ru. Ngày 5, ngày 10: địa ngục.

Transaction Service của anh Khoa là trung tâm của hệ thống thanh toán. Mỗi giao dịch cần:

1. Gọi **Profile Service** - lấy thông tin khách hàng
2. Gọi **SOF Service** - xác minh nguồn tiền
3. Gọi **Core Banking** - thực hiện giao dịch

Tất cả qua RabbitMQ RPC. Và khi một mắt xích chậm, domino effect kéo theo tất cả.

Anh Khoa đã thử mọi cách:
- Tăng timeout? Chỉ làm request chờ lâu hơn trước khi fail
- Retry? Làm tăng load, tình hình tệ hơn
- Circuit breaker? Khách hàng vẫn không giao dịch được

Mỗi cuộc họp, câu chuyện cũ lặp lại. Mỗi cuộc họp, không ai nhường ai.

## Cuộc gọi lúc 10 giờ đêm

Một tối muộn, anh Khoa gọi cho tôi.

> "Em ơi, anh không biết phải làm sao nữa. Mỗi tháng cứ đến ngày peak là anh mất ngủ. Team anh bị blame, nhưng anh nhìn code, nhìn metrics, không biết fix ở đâu. Profile nói họ nhanh. DevOps nói RabbitMQ ổn. Vậy cái gì chậm?"

Giọng anh không còn sự cứng rắn như trong phòng họp. Đó là giọng của một người đã kiệt sức.

> "Anh có một giả thuyết," anh nói tiếp. "Có thể message của anh nằm trên queue mà không ai lấy ra xử lý. Hoặc nằm đâu đó trong network. Nhưng anh không chứng minh được."

Tôi im lặng nghe. Đôi khi, điều người ta cần không phải là giải pháp, mà là ai đó lắng nghe.

![Late Night](https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800)

## CTO vào cuộc

Sau nhiều cuộc họp căng thẳng không đi đến đâu, CTO quyết định tham gia trực tiếp.

Cuộc họp tiếp theo, anh mang theo một bảng trắng.

> "Hôm nay chúng ta sẽ không tranh luận ai đúng ai sai," anh nói. "Chúng ta sẽ cùng nhìn vào những con số."

Anh Đạt cho biết Profile Service hiện tại:
- **4,000 RPS** (requests per second)
- **40 pods**
- Latency trung bình: **40ms**

CTO viết lên bảng:

```
Mỗi pod nhận: 4,000 / 40 = 100 RPS
```

> "Với latency 40ms, mỗi pod xử lý đồng thời bao nhiêu request?"

Anh Đạt tính nhẩm: "100 nhân 0.04... khoảng 4 concurrent requests."

CTO gật đầu, viết tiếp:

```
Little's Law: Concurrency = RPS × Latency
Concurrency = 100 × 0.04 = 4 requests
```

> "Bây giờ," anh hỏi, "nếu latency không còn là 40ms, mà là 200ms thì sao?"

## Con số không ai muốn nghe

Cả phòng im lặng khi CTO viết:

```
Concurrency mới = 100 × 0.2 = 20 requests
```

Từ 4 lên 20. **Gấp 5 lần.**

> "Mỗi pod vẫn nhận 100 RPS," CTO giải thích. "Load balancer không quan tâm pod của bạn đang xử lý nhanh hay chậm. Nó cứ chia đều. Nhưng khi latency tăng, số request tồn đọng trong pod tăng theo."

Anh Đạt nhíu mày: "Nhưng CPU, memory bên em vẫn bình thường mà."

> "Đúng. Vì pod chưa đến ngưỡng quá tải về resource. Nhưng có thể đã quá tải về **concurrency**. Thread pool có thể đầy. Connection pool có thể cạn. Event loop có thể bị block."

Tôi chen vào: "Vậy nếu muốn giữ concurrency ở mức 4 như cũ?"

CTO viết:

```
RPS mỗi pod = 4 / 0.2 = 20 RPS
Số pod cần = 4,000 / 20 = 200 pods
```

200 pods. Từ 40 lên 200. **Gấp 5 lần** - đúng bằng tỷ lệ latency tăng.

![Whiteboard](https://images.unsplash.com/photo-1596495577886-d920f1fb7238?w=800)

## "Nhưng latency tăng từ đâu?"

Câu hỏi của anh Đạt treo lơ lửng trong phòng.

> "Bên em internal là 40ms. Vậy 160ms còn lại ở đâu?"

Không ai có câu trả lời.

- **Queue delay?** DevOps nói queue depth bình thường
- **Network?** Các service khác cùng network không bị
- **RabbitMQ internal?** Metrics không cho thấy gì bất thường
- **HAProxy?** Không có dấu hiệu nghẽn

CTO nhìn quanh phòng:

> "Chúng ta đang đo được **đầu** và **cuối**, nhưng không đo được **giữa**."

Request rời khỏi Transaction Service - đo được.
Response trả về Transaction Service - đo được.
Profile Service nhận request và xử lý - đo được.

Nhưng:
- Request nằm trong RabbitMQ bao lâu trước khi được consumer lấy ra?
- Response nằm trong reply queue bao lâu?
- Network latency giữa các hop?

**Không ai đo.**

## Giả thuyết trong bóng tối

CTO đưa ra một giả thuyết - không phải để khẳng định, mà để mọi người cùng suy nghĩ:

> "Có thể vào ngày peak, consumer của Profile không lấy message kịp. Không phải vì xử lý chậm, mà vì **prefetch** hoặc **channel** bị nghẽn. Message nằm đợi trong queue - không đủ lâu để queue depth tăng đáng kể, nhưng đủ để cộng dồn latency."

Anh Đạt gật đầu chậm rãi: "Có thể. Nhưng làm sao chứng minh?"

> "Cần thêm metrics. Đo thời gian từ lúc publish đến lúc consume. Đo queue wait time, không chỉ queue depth."

Anh Hiền ghi chép: "Tôi sẽ thêm monitoring cho phần này."

Nhưng tất cả chúng tôi đều biết: đây chỉ là **một** giả thuyết trong hàng tá giả thuyết khác.

## Quyết định trong sương mù

Hai tuần sau. Metrics mới vẫn chưa đủ kết luận. Ngày mùng 5 sắp đến. Áp lực từ business ngày càng lớn.

Trong một cuộc họp khác, anh Khoa đề xuất:

> "Em muốn thử gRPC."

Cả phòng nhìn anh ấy.

> "Thay vì gọi Profile qua RabbitMQ, em gọi trực tiếp qua gRPC. Không queue, không broker ở giữa. Nếu latency giảm, ít nhất chúng ta biết vấn đề nằm ở đâu đó trong RabbitMQ layer."

Anh Đạt không phản đối: "Bên em có thể expose gRPC endpoint. Không khó."

Đây không phải giải pháp hoàn hảo. Đây là **thí nghiệm**. Một cách để thu hẹp phạm vi nghi ngờ.

![Crossroads](https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800)

## Kết quả

Hai tuần sau khi triển khai gRPC cho một phần traffic:

**Latency giảm 60%.**

Anh Khoa gọi điện cho tôi, giọng nhẹ nhõm hơn nhiều:

> "Em ơi, ngày mùng 10 vừa rồi êm ru. Phần gọi Profile qua gRPC không có vấn đề gì."

Nhưng CTO hỏi trong cuộc họp review: "Vậy chúng ta kết luận được gì?"

Cả phòng im lặng.

Anh Khoa trả lời thật: "Em... không chắc. Có thể RabbitMQ là vấn đề. Có thể gRPC đơn giản là nhanh hơn. Có thể cả hai. Em không thể nói chắc 100%."

Đó là sự thật. gRPC nhanh hơn inherently - binary protocol, HTTP/2, multiplexing. Có thể cải thiện không phải vì RabbitMQ "sai", mà vì gRPC "đúng hơn" cho use case này.

**Chúng tôi vẫn không biết chắc vấn đề ban đầu nằm ở đâu.**

## Kết bài không có hồi kết

Đây là thực tế của distributed systems.

Không phải câu chuyện nào cũng có villain rõ ràng để đánh bại. Không phải bug nào cũng có root cause để fix. Đôi khi, bạn phải chấp nhận **uncertainty** và tiến về phía trước với **best available option**.

RabbitMQ vẫn chạy trong hệ thống của chúng tôi - cho những use case phù hợp. gRPC được dùng cho những chỗ cần latency thấp và direct communication.

Anh Khoa vẫn làm Tech Lead team Transaction. Anh Đạt vẫn phụ trách Profile. Họ vẫn thỉnh thoảng tranh luận trong phòng họp - nhưng giờ đây, với sự tôn trọng nhiều hơn. Vì cả hai đều hiểu: trong distributed systems, đôi khi **ai cũng đúng, nhưng hệ thống vẫn có thể sai**.

Và đó cũng là một bài học.

![Ending](https://images.unsplash.com/photo-1527482797697-8795b05a13fe?w=800)

---

## Little's Law - Công thức đáng nhớ

```
L = λ × W

Trong đó:
- L = Số request đang xử lý đồng thời (concurrency)
- λ = Tốc độ request đến (RPS)
- W = Thời gian xử lý (latency)
```

Khi thiết kế hệ thống:
- **Latency tăng 5 lần** → Concurrency tăng 5 lần → **Scale 5 lần**
- Scale giải quyết triệu chứng, **không giải quyết nguyên nhân**
- Đo được đầu cuối chưa đủ - cần đo **từng chặng**

---

## Series "Bé Thỏ"

| Phần | Tiêu đề | Bài học |
|------|---------|---------|
| [Phần 1](/vi/blog/be-tho-part-1) | Khi HTTP không còn đủ | Competing consumers, natural load balancing |
| [Phần 2](/vi/blog/be-tho-part-2) | Những cái bẫy chết người | Singleton pattern, channel/queue management |
| [Phần 3](/vi/blog/be-tho-part-3) | Đêm 500 ngàn connections | Connection storm, reconnect limits |
| [Phần 4](/vi/blog/be-tho-part-4) | Cuộc chiến không có kẻ thắng | Little's Law, accept uncertainty |

---

*Cảm ơn bạn đã đọc đến đây. Distributed systems là một cuộc hành trình không có đích đến - chỉ có những bài học dọc đường.*

*Và đôi khi, bài học lớn nhất là: không phải câu hỏi nào cũng có câu trả lời.*
